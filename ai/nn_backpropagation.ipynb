{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks - Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we go through the forward propagation of a simple neural network and then step by step details of the backpropagation using computational graph and chain rule. \n",
    "\n",
    "Let's say we have the following neural network which is used for binary classification. We have the following: \n",
    "\n",
    "**Input**:<br>\n",
    "2 samples with 2 features\n",
    "\n",
    "**Network Architecture**:<br>\n",
    "- Layer 1: Fully connected layer with 3 neurons and ReLU activation function.\n",
    "- Layer 2: Fully connected layer with 2 neurons and ReLU activation function.\n",
    "- Layer 3 (output): Fully connected layer with 1 neuron (output) and Sigmoid activation function.\n",
    "\n",
    "**Loss function**:<br>\n",
    "Binary Cross Entropy\n",
    "\n",
    "![](https://pooya.io/ai/images/nn_backpropagation.svg)\n",
    "For more details see [Neural Networks Propagation](https://pooya.io/ai/neural-networks-backpropagation/).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In this example we use a batch dataset with 2 samples. The input $X$ and target $Y$ are defined as follows:\n",
    "\n",
    "$$X = \\begin{bmatrix} 1 & 2 \\\\ 3 & 4 \\end{bmatrix}$$\n",
    "$$\\vec{\\mathbf{y}} = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$$\n",
    "\n",
    "Which means, for example 1 $x_1 = 1$ and $x_2 = 2$ and the target class $y = 0$.\n",
    "\n",
    "Recall that we maintain each sample in **rows** and features in **columns**. So, each row of $X$ and $\\vec{\\mathbf{y}}$ is associated with one sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "X = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
    "y = torch.tensor([[0.0], [1.0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create our neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "\n",
    "        # Define the model architecture (Layers and nodes)\n",
    "        self.linear1 = nn.Linear(in_features=2, out_features=3)\n",
    "        self.linear2 = nn.Linear(in_features=3, out_features=2)\n",
    "        self.linear3 = nn.Linear(in_features=2, out_features=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward Propagation happens here.\n",
    "        # It takes the input tensor x and returns the output tensor for each\n",
    "        # layer by applying the linear transformation first and then the\n",
    "        # activation function.\n",
    "        # It start from layer 1 and goes forward layer by layer to the output\n",
    "        # layer.\n",
    "\n",
    "        # Layer 1 linear transformation\n",
    "        Z1 = self.linear1(x)\n",
    "        # Layer 1 activation\n",
    "        A1 = F.relu(Z1)\n",
    "\n",
    "        # Layer 2 linear transformation\n",
    "        Z2 = self.linear2(A1)\n",
    "        # Layer 2 activation\n",
    "        A2 = F.relu(Z2)\n",
    "\n",
    "        # Layer 3 (output layer) linear transformation\n",
    "        Z3 = self.linear3(A2)\n",
    "        # Layer 3 activation\n",
    "        A3 = F.sigmoid(Z3)\n",
    "\n",
    "        # Output of the model A3, along with the intermediate results\n",
    "        return A3, {\"Z1\": Z1, \"A1\": A1, \"Z2\": Z2, \"A2\": A2, \"Z3\": Z3}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, for classification problems, when we use the Sigmoid or Softmax activation function in the output layer, we defer the activation of the output layer to the outside the model. In other words, the output layer just do the linear transformation $Z$ and output the [logits](). Then we apply the activatio function (Sigmoid or Softmax) outside the model on the logits to get the predicted probabilities.\n",
    "\n",
    "This approach is the same for both inference and training.\n",
    "\n",
    "However, in this example, for simplicity and focus on the backpropagation, we will include the Sigmoid activation function in the output layer. So, in this example, the output layer will output the predicted probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNet(\n",
      "  (linear1): Linear(in_features=2, out_features=3, bias=True)\n",
      "  (linear2): Linear(in_features=3, out_features=2, bias=True)\n",
      "  (linear3): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNet()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the initial weights and biases of our neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1: Linear\n",
      "\n",
      "weight: torch.Size([3, 2]) Parameter containing:\n",
      "tensor([[ 0.5395,  0.6596],\n",
      "        [-0.6296, -0.4057],\n",
      "        [ 0.4303,  0.0345]], requires_grad=True)\n",
      "weight.grad:\n",
      "None\n",
      "\n",
      "bias: torch.Size([3]) Parameter containing:\n",
      "tensor([0.6199, 0.6223, 0.1412], requires_grad=True)\n",
      "bias.grad:\n",
      "None\n",
      "--------------------------------------------------------------------------------\n",
      "Layer 2: Linear\n",
      "\n",
      "weight: torch.Size([2, 3]) Parameter containing:\n",
      "tensor([[ 0.2129, -0.3841,  0.3624],\n",
      "        [-0.4972,  0.2257,  0.5195]], requires_grad=True)\n",
      "weight.grad:\n",
      "None\n",
      "\n",
      "bias: torch.Size([2]) Parameter containing:\n",
      "tensor([-0.4477,  0.2886], requires_grad=True)\n",
      "bias.grad:\n",
      "None\n",
      "--------------------------------------------------------------------------------\n",
      "Layer 3: Linear\n",
      "\n",
      "weight: torch.Size([1, 2]) Parameter containing:\n",
      "tensor([[-0.3017, -0.4939]], requires_grad=True)\n",
      "weight.grad:\n",
      "None\n",
      "\n",
      "bias: torch.Size([1]) Parameter containing:\n",
      "tensor([-0.3963], requires_grad=True)\n",
      "bias.grad:\n",
      "None\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def print_model_parameters(model):\n",
    "    for i, child in enumerate(model.children()):\n",
    "        print(f\"Layer {i+1}: {type(child).__name__}\")\n",
    "        child_parameters = dict(child.named_parameters())\n",
    "\n",
    "        for name, param in child_parameters.items():\n",
    "            print(f\"\\n{name}: {param.size()} {param}\")\n",
    "            print(f\"{name}.grad:\\n{param.grad}\")\n",
    "\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "\n",
    "print_model_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we expect, gradients of parameters are `None` since we haven't computed any gradients yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example for simplicity and having reproducible results, we'll set the weights and biases manually. Let's say we have the following weights and biases:\n",
    "\n",
    "Similar to the way that PyTorch creates weights matrices:\n",
    "- Each row of $W^{[l]}$ is associated with one neuron in the layer $l$. For example, in layer 1, We have 3 neurons, so we have 3 rows in $W^{[1]}$.\n",
    "- Each column of $W^{[l]}$ is associated with one feature of input values. For example, the number of columns in $W^{[1]}$ is equal to the number of features in the input layer $X$. We have 2 features in the input layer $X$, so we have 2 columns in $W^{[1]}$.\n",
    "\n",
    "\n",
    "**Layer 1 (3 neurons):**\n",
    "$$W^{[1]} = \\begin{bmatrix} -1 & 2 \\\\ 3 & 0.5 \\\\ -0.1 & -4\\end{bmatrix} \\quad {\\vec{\\mathbf{b}}}^{[1]} = \\begin{bmatrix} 1 & -2 & 0.3 \\end{bmatrix}$$\n",
    "\n",
    "\n",
    "**Layer 2 (2 neurons):**\n",
    "$$W^{[2]} = \\begin{bmatrix} 0.5 & 1 & -2 \\\\ 0.7 & 0.1 & 0.3\\end{bmatrix} \\quad {\\vec{\\mathbf{b}}}^{[2]} = \\begin{bmatrix} -4 & 5 \\end{bmatrix}$$\n",
    "\n",
    "**Layer 3 (output):**\n",
    "$$W^{[3]} = \\begin{bmatrix} 0.5 & -0.3 \\end{bmatrix} \\quad {\\vec{\\mathbf{b}}}^{[3]} = \\begin{bmatrix} 0.1 \\end{bmatrix}$$ \n",
    "\n",
    "Note: The number of weight and biases are independent of the number of training samples (in any batch or entire dataset). The whole point of training with sample datasets is to optimize these parameters by exposing them to the entire dataset through cycle of forward and backward propagation. So, no matter what is the size of the dataset, the number of parameters in the model is fixed and defined by the architecture of the neural network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer 1\n",
    "W1 = torch.tensor([[-1.0, 2.0], [3.0, 0.5], [-0.1, -4.0]], requires_grad=True)\n",
    "b1 = torch.tensor([1.0, -2.0, 0.3], requires_grad=True)\n",
    "\n",
    "# Layer 2\n",
    "W2 = torch.tensor([[0.5, 1.0, -2.0], [0.7, 0.1, 0.3]], requires_grad=True)\n",
    "b2 = torch.tensor([-4.0, 5.0], requires_grad=True)\n",
    "\n",
    "# Layer 3 (Output layer)\n",
    "W3 = torch.tensor([[0.5, -0.3]], requires_grad=True)\n",
    "b3 = torch.tensor([0.1], requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we set these weights and biases in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1: Linear\n",
      "\n",
      "weight: torch.Size([3, 2]) Parameter containing:\n",
      "tensor([[-1.0000,  2.0000],\n",
      "        [ 3.0000,  0.5000],\n",
      "        [-0.1000, -4.0000]], requires_grad=True)\n",
      "weight.grad:\n",
      "None\n",
      "\n",
      "bias: torch.Size([3]) Parameter containing:\n",
      "tensor([ 1.0000, -2.0000,  0.3000], requires_grad=True)\n",
      "bias.grad:\n",
      "None\n",
      "--------------------------------------------------------------------------------\n",
      "Layer 2: Linear\n",
      "\n",
      "weight: torch.Size([2, 3]) Parameter containing:\n",
      "tensor([[ 0.5000,  1.0000, -2.0000],\n",
      "        [ 0.7000,  0.1000,  0.3000]], requires_grad=True)\n",
      "weight.grad:\n",
      "None\n",
      "\n",
      "bias: torch.Size([2]) Parameter containing:\n",
      "tensor([-4.,  5.], requires_grad=True)\n",
      "bias.grad:\n",
      "None\n",
      "--------------------------------------------------------------------------------\n",
      "Layer 3: Linear\n",
      "\n",
      "weight: torch.Size([1, 2]) Parameter containing:\n",
      "tensor([[ 0.5000, -0.3000]], requires_grad=True)\n",
      "weight.grad:\n",
      "None\n",
      "\n",
      "bias: torch.Size([1]) Parameter containing:\n",
      "tensor([0.1000], requires_grad=True)\n",
      "bias.grad:\n",
      "None\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model.linear1.weight.data.copy_(W1)\n",
    "model.linear1.bias.data.copy_(b1)\n",
    "\n",
    "model.linear2.weight.data.copy_(W2)\n",
    "model.linear2.bias.data.copy_(b2)\n",
    "\n",
    "model.linear3.weight.data.copy_(W3)\n",
    "model.linear3.bias.data.copy_(b3)\n",
    "\n",
    "print_model_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Forward Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run the forward propagation using the current weights and biases, and the input $X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intermediate results:\n",
      "Z1:\n",
      "tensor([[  4.0000,   2.0000,  -7.8000],\n",
      "        [  6.0000,   9.0000, -16.0000]], grad_fn=<AddmmBackward0>)\n",
      "A1:\n",
      "tensor([[4., 2., 0.],\n",
      "        [6., 9., 0.]], grad_fn=<ReluBackward0>)\n",
      "Z2:\n",
      "tensor([[ 0.0000,  8.0000],\n",
      "        [ 8.0000, 10.1000]], grad_fn=<AddmmBackward0>)\n",
      "A2:\n",
      "tensor([[ 0.0000,  8.0000],\n",
      "        [ 8.0000, 10.1000]], grad_fn=<ReluBackward0>)\n",
      "Z3:\n",
      "tensor([[-2.3000],\n",
      "        [ 1.0700]], grad_fn=<AddmmBackward0>)\n",
      "A3 (Model Output):\n",
      "tensor([[0.0911],\n",
      "        [0.7446]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Forward Propagation\n",
    "output, model_results = model(X)\n",
    "\n",
    "# Print the intermediate results\n",
    "print(\n",
    "    \"Intermediate results:\\n\"\n",
    "    f\"Z1:\\n{model_results[\"Z1\"]}\\n\"\n",
    "    f\"A1:\\n{model_results[\"A1\"]}\\n\"\n",
    "    f\"Z2:\\n{model_results[\"Z2\"]}\\n\"\n",
    "    f\"A2:\\n{model_results[\"A2\"]}\\n\"\n",
    "    f\"Z3:\\n{model_results[\"Z3\"]}\\n\"\n",
    "    f\"A3 (Model Output):\\n{output}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll follow the steps manually to understand the computational graph and forward propagation.\n",
    "\n",
    "![](https://pooya.io/ai/images/nn_computational_graph.svg)\n",
    "\n",
    "As it shown in the above graph, we start from the first node and go through the graph from left to right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In [Forward Propagation]() we feed the input $X$ (which could be a single sample, a batch of samples, or the entire dataset) to the model and then compute the output of first layer, then give that output to the next layer (as input) and compute the output of the next layer, and so on until we reach the output layer.\n",
    "\n",
    "In each layer, we have two steps of computation:\n",
    "\n",
    "**1. Linear Transformation:**<br>\n",
    "$$Z^{[l]} = A^{[l-1]} \\cdot {W^{[l]}}^\\top + {\\vec{\\mathbf{b}}}^{[l]}$$\n",
    "\n",
    "**2. Activation Function:**<br>\n",
    "$$A^{[l]} = g^{[l]}(Z^{[l]})$$\n",
    "\n",
    "By convention, we consider $X$ as the layer $0$. So, $A^{[0]} = X$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the output of the layer $1$.\n",
    "\n",
    "**Layer 1:**\n",
    "$$Z^{[1]} = X \\cdot {W^{[1]}}^\\top + {\\vec{\\mathbf{b}}}^{[1]}$$\n",
    "\n",
    "$$Z^{[1]} = \\begin{bmatrix} 1 & 2 \\\\ 3 & 4 \\end{bmatrix} \\cdot \\begin{bmatrix} -1 & 3 & -0.1 \\\\ 2 & 0.5 & -4 \\end{bmatrix} + \\begin{bmatrix} 1 & -2 & 0.3 \\end{bmatrix}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Z^{[1]} = \\begin{bmatrix} 3 & 4 & -8.1 \\\\ 5 & 11 & -16.3 \\end{bmatrix} + \\begin{bmatrix} 1 & -2 & 0.3 \\end{bmatrix}$$\n",
    "\n",
    "We broadcast the bias vector to the shape of $(2, 3)$ and add it to the dot product of $X$ and $W^{[1]}$.\n",
    "\n",
    "$$Z^{[1]} = \\begin{bmatrix} 3 & 4 & -8.1 \\\\ 5 & 11 & -16.3 \\end{bmatrix} + \\begin{bmatrix} 1 & -2 & 0.3 \\\\ 1 & -2 & 0.3 \\end{bmatrix} = \\begin{bmatrix} 4 & 2 & -7.8 \\\\ 6 & 9 & -16 \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify our calculation using numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_np = X.numpy()\n",
    "W1_np = W1.detach().numpy()\n",
    "b1_np = b1.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z1 (using numpy):\n",
      "[[  4.         2.        -7.8     ]\n",
      " [  6.         9.       -15.999999]]\n"
     ]
    }
   ],
   "source": [
    "Z1 = np.dot(X_np, W1_np.T) + b1_np\n",
    "\n",
    "print(f\"Z1 (using numpy):\\n{Z1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: due to how floating point arithmetic works in computer hardware, the result of $-16.3 + 0.3$ is not exactly $-16$ but a number very close to $-16$ like $-15.9999...$.\n",
    "> For example, `print(0.1 + 0.2)` will output `0.30000000000000004` instead of `0.3`. This is not a bug, it's a limitation of floating point arithmetic in computers and it's not specific to Python or PyTorch.\n",
    "> \n",
    "> However, this is not a problem in practice in machine learning and deep learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's calculate the activation of layer 1 using the [ReLU]() activation function.\n",
    "\n",
    "$$A^{[1]} = \\text{ReLU}(Z^{[1]})$$\n",
    "\n",
    "$$A^{[1]} = \\begin{bmatrix} \\text{ReLU}(4) & \\text{ReLU}(2) & \\text{ReLU}(-7.8) \\\\ \\text{ReLU}(6) & \\text{ReLU}(9) & \\text{ReLU}(-16) \\end{bmatrix}$$\n",
    "\n",
    "We know that the ReLU function is defined as:\n",
    "$$\\text{ReLU}(z) = \\max(0, z)$$\n",
    "\n",
    "We apply ReLU element-wise to the matrix $Z^{[1]}$. So, the output of the layer 1 is: \n",
    "\n",
    "$$A^{[1]} = \\begin{bmatrix} 4 & 2 & 0 \\\\ 6 & 9 & 0 \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify our calculation using numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(Z):\n",
    "    return np.maximum(0, Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1 (using numpy):\n",
      "[[4. 2. 0.]\n",
      " [6. 9. 0.]]\n"
     ]
    }
   ],
   "source": [
    "A1 = relu(Z1)\n",
    "\n",
    "print(f\"A1 (using numpy):\\n{A1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we compare this result with the PyTorch output, we see that they are the same.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's calculate the output of the layer 2.\n",
    "\n",
    "**Layer 2:**\n",
    "\n",
    "$$Z^{[2]} = A^{[1]} \\cdot {W^{[2]}}^\\top + {\\vec{\\mathbf{b}}}^{[2]}$$\n",
    "\n",
    "$$Z^{[2]} = \\begin{bmatrix} 4 & 2 & 0 \\\\ 6 & 9 & 0 \\end{bmatrix} \\cdot \\begin{bmatrix} 0.5 & 0.7 \\\\ 1 & 0.1 \\\\ -2 & 0.3 \\end{bmatrix} + \\begin{bmatrix} -4 & 5 \\end{bmatrix}$$\n",
    "\n",
    "Which equals to:\n",
    "\n",
    "$$Z^{[2]} = \\begin{bmatrix} 0 & 8 \\\\ 8 & 10.1 \\end{bmatrix}$$\n",
    "\n",
    "And then applying the ReLU activation function:\n",
    "\n",
    "$$A^{[2]} = \\begin{bmatrix} 0 & 8 \\\\ 8 & 10.1 \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the same way, we can keep going **forward** and compute the outputs (linear transformations and activations) layer by layer until we reach the output layer.\n",
    "\n",
    "The output of the output layer is the **prediction** of the model which in this case is the predicted probability of binary classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Compute the Loss and Cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the cost will provide the error of our model in respect to the labels (target value $Y$). To calculate the loss function, we continue moving forward (left to right) in the computational graph.\n",
    "\n",
    "The [cost]() function is usually the average of the [loss]() function over all the samples in the batch (which pass through in the forward propagation).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss function for binary classification is the binary cross-entropy loss which is defined as:\n",
    "\n",
    "$$L_{BCE}(\\theta)^{(i)} = -y^{(i)} \\log(f_{\\theta}(x^{(i)})) - (1-y^{(i)}) \\log(1 - f_{\\theta}(x^{(i)}))$$\n",
    "\n",
    "Where:\n",
    "- $i$ is the index of the sample in the batch.\n",
    "- $y$ is the target value (label) of the $i$-th sample.\n",
    "- $\\theta$ is the model's parameters (weights and biases).\n",
    "- $f_{\\theta}$ is the model's function which produces the predicted probability based on the input $x$ and the model's parameters $\\theta$. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [cost]() function is the average of the loss function over all the samples in the batch.\n",
    "\n",
    "$$J(\\theta) = \\frac{1}{m} \\sum_{i=1}^{m} L(\\theta)^{(i)}$$\n",
    "\n",
    "Where:\n",
    "- $m$ is the number of samples in the batch.\n",
    "\n",
    "For more details see [Loss and Cost Functions in Machine Learning]()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using pytorch builtin cost function we can calculate the cost as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 0.19522885978221893\n"
     ]
    }
   ],
   "source": [
    "cost = F.binary_cross_entropy(output, y)\n",
    "\n",
    "print(f\"Cost: {cost}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we discussed earlier, for more stable computation, in practice, we usually don't include the activation function in the output layer. So, the output of the model is the linear transformation $Z$ of the output layer (logits).  \n",
    "\n",
    "In this example, for simplicity, we include the Sigmoid activation function in the output layer. So, the `output` is the predicted probabilities. We will use `binary_cross_entropy()` loss function to calculate the loss. If we had deferred the activation function to the outside of the model, then the output would be the logits of the output layer, which then we should have used `binary_cross_entropy_with_logits()` loss function instead.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how this cost is calculated. We'll use numpy to calculate the cost manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Recall that all of our calculations are matrix operations where each row is associated with one sample in the batch.  \n",
    "\n",
    "This is the Loss of output matrix $A^{[3]}$:\n",
    "\n",
    "$$L(\\theta) = -\\vec{\\mathbf{y}} \\cdot \\log(A^{[3]}) - (1-\\vec{\\mathbf{y}}) \\cdot \\log(1 - A^{[3]})$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$L(\\theta) = -\\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} \\cdot \\log(\\begin{bmatrix} 0.0911 \\\\ 0.7446 \\end{bmatrix}) - \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} \\cdot \\log(\\begin{bmatrix} 1 - 0.0911 \\\\ 1 - 0.7446 \\end{bmatrix})$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Element-wise operations:\n",
    "\n",
    "$$L(\\theta) = -\\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} \\odot \\begin{bmatrix} -2.3955 \\\\ -0.2949 \\end{bmatrix} - \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} \\odot \\begin{bmatrix} -0.0955 \\\\ -1.3649 \\end{bmatrix}$$\n",
    "\n",
    "> Note: $\\odot$ is the element-wise multiplication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$L(\\theta) = \\begin{bmatrix} 0 \\\\ 0.2949 \\end{bmatrix} - \\begin{bmatrix} -0.0955 \\\\ 0 \\end{bmatrix} = \\begin{bmatrix} 0.0955 \\\\ 0.2949 \\end{bmatrix}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, in order to calculate the cost, we take the average of the loss of all samples in the batch.\n",
    "\n",
    "$$J(\\theta) = \\frac{1}{2} \\sum_{i=1}^{2} L(\\theta)^{(i)} = \\frac{0.0955 + 0.2949}{2} = 0.1952$$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify our calculation using numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_np = y.numpy()\n",
    "A3 = output.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss (using numpy):\n",
      "[[0.09554543]\n",
      " [0.29491228]]\n"
     ]
    }
   ],
   "source": [
    "L_np = -1 * (y_np * np.log(A3) + (1 - y_np) * np.log(1 - A3))\n",
    "\n",
    "print(f\"Loss (using numpy):\\n{L_np}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, calculating the cost by taking the average of the loss of all samples in the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost (using numpy):\n",
      "0.19522884488105774\n"
     ]
    }
   ],
   "source": [
    "cost_np = np.mean(L_np)\n",
    "\n",
    "print(f\"Cost (using numpy):\\n{cost_np}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see we have reached the same value for the cost as PyTorch. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we calculate the output (inference) of the model and the cost (error) of the model in comparison with the target values. Now we need to start optimizing the model's parameters by minimizing the error (cost). For doing this we need to calculate the gradients of the cost function with respect to the model's parameters (weights and biases) and then update the parameters using the gradients.\n",
    "\n",
    "\n",
    "The backpropagation algorithm is a method for calculating the gradients of the cost function with respect to the model's parameters (weights and biases) using the chain rule of calculus and the computational graph of the neural network. \n",
    "\n",
    "In backprop, we calculate the gradients of the loss function with respect to each parameter of the model. As we discussed in the [Backward Propagation](), we start from the last node of the computational graph (the cost node) and then calculate the partial derivative (gradient) of the loss with respect to each part of the graph step by step in backward direction until we reach to all the parameters of the model. Hence, the name **backpropagation** or **backward pass**.\n",
    "\n",
    "**Right-to-Left**<br>\n",
    "![](https://pooya.io/ai/images/nn_computational_graph.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Using Chain Rule:**<br>\n",
    "We can see the whole model as a huge composite function which is made of many smaller functions (linear transformation and activation function of each layer). These functions are composed together layer by layer like a chain. So, in simple terms we can say that we use chain rule to calculate the gradient of the loss with respect to each parameter from the most outer function (cost) to the most inner function (parameters of the model).\n",
    "\n",
    "**Gradient of Loss vs Cost**:<br>\n",
    "We calculate the partial derivative of the **loss** with respect to each parameter of the model. That gives us the gradient of the loss with respect to each parameter for **one single sample**. Then we calculate the average of these gradients (mean gradient) over all the samples in the batch. In that case, we can say we have calculated the gradient of the **cost** with respect to each parameter of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start the backward propagation by first defining our optimizer. We use [Adam]() variation of the [SGD (Stochastic Gradient Descent)]() algorithm to calculate the gradients and then update the parameters of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Define Adam optimizer with learning rate of 0.01\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By convention, we usually set all the gradients to zero before starting any new computation. Since PyTorch stores the gradients in the parameters, resetting them (using `zero_grad()`) is a good practice before calculating new gradients.\n",
    "\n",
    "In this particular example, as we haven't calculated any gradients yet, the gradients are `None`. So, resetting them has no effect. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1: Linear\n",
      "\n",
      "weight: torch.Size([3, 2]) Parameter containing:\n",
      "tensor([[-1.0000,  2.0000],\n",
      "        [ 3.0000,  0.5000],\n",
      "        [-0.1000, -4.0000]], requires_grad=True)\n",
      "weight.grad:\n",
      "None\n",
      "\n",
      "bias: torch.Size([3]) Parameter containing:\n",
      "tensor([ 1.0000, -2.0000,  0.3000], requires_grad=True)\n",
      "bias.grad:\n",
      "None\n",
      "--------------------------------------------------------------------------------\n",
      "Layer 2: Linear\n",
      "\n",
      "weight: torch.Size([2, 3]) Parameter containing:\n",
      "tensor([[ 0.5000,  1.0000, -2.0000],\n",
      "        [ 0.7000,  0.1000,  0.3000]], requires_grad=True)\n",
      "weight.grad:\n",
      "None\n",
      "\n",
      "bias: torch.Size([2]) Parameter containing:\n",
      "tensor([-4.,  5.], requires_grad=True)\n",
      "bias.grad:\n",
      "None\n",
      "--------------------------------------------------------------------------------\n",
      "Layer 3: Linear\n",
      "\n",
      "weight: torch.Size([1, 2]) Parameter containing:\n",
      "tensor([[ 0.5000, -0.3000]], requires_grad=True)\n",
      "weight.grad:\n",
      "None\n",
      "\n",
      "bias: torch.Size([1]) Parameter containing:\n",
      "tensor([0.1000], requires_grad=True)\n",
      "bias.grad:\n",
      "None\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print_model_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that each parameter (which has `requires_grad=True`) has a `grad` attribute which stores the gradient of the loss with respect to that parameter. We can see that all of our parameters currently has `None` as their gradients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run the backpropagation by calling the `backward()` method on the last node of the computational graph (the cost node). This will start the backward step by step calculation of the gradients of the cost with respect to each parameter of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backpropagation (compute the gradients)\n",
    "cost.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1: Linear\n",
      "\n",
      "weight: torch.Size([3, 2]) Parameter containing:\n",
      "tensor([[-1.0000,  2.0000],\n",
      "        [ 3.0000,  0.5000],\n",
      "        [-0.1000, -4.0000]], requires_grad=True)\n",
      "weight.grad:\n",
      "tensor([[-0.0249, -0.0396],\n",
      "        [-0.1814, -0.2428],\n",
      "        [ 0.0000,  0.0000]])\n",
      "\n",
      "bias: torch.Size([3]) Parameter containing:\n",
      "tensor([ 1.0000, -2.0000,  0.3000], requires_grad=True)\n",
      "bias.grad:\n",
      "tensor([-0.0147, -0.0614,  0.0000])\n",
      "--------------------------------------------------------------------------------\n",
      "Layer 2: Linear\n",
      "\n",
      "weight: torch.Size([2, 3]) Parameter containing:\n",
      "tensor([[ 0.5000,  1.0000, -2.0000],\n",
      "        [ 0.7000,  0.1000,  0.3000]], requires_grad=True)\n",
      "weight.grad:\n",
      "tensor([[-0.3831, -0.5747,  0.0000],\n",
      "        [ 0.1752,  0.3175,  0.0000]])\n",
      "\n",
      "bias: torch.Size([2]) Parameter containing:\n",
      "tensor([-4.,  5.], requires_grad=True)\n",
      "bias.grad:\n",
      "tensor([-0.0639,  0.0246])\n",
      "--------------------------------------------------------------------------------\n",
      "Layer 3: Linear\n",
      "\n",
      "weight: torch.Size([1, 2]) Parameter containing:\n",
      "tensor([[ 0.5000, -0.3000]], requires_grad=True)\n",
      "weight.grad:\n",
      "tensor([[-1.0216, -0.9253]])\n",
      "\n",
      "bias: torch.Size([1]) Parameter containing:\n",
      "tensor([0.1000], requires_grad=True)\n",
      "bias.grad:\n",
      "tensor([-0.0821])\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print_model_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's simulate the backpropagation manually step by step. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember we start with the final node and walk backward the computational graph. So, we start with the cost node and calculate the gradient of the cost with respect to the output of the output layer.\n",
    "\n",
    "Also, recall the word **partial derivative** and **gradient** mean the same thing and we use them interchangeably.\n",
    "\n",
    "As we discussed earlier, we calculate the gradient of **loss** with respect to each parameter of the model. We do this for all of the calculations. At the end, we calculate the average of these gradients (mean gradient) over all the samples in the batch to give the gradient of the **cost** with respect to each parameter of the model.\n",
    "\n",
    "So, all the following steps are computing the gradient of the **loss** with respect to each parameter of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Gradient of $L$ with respect to $A^{[3]}$\n",
    "\n",
    "We are at the end of the computational graph (the loss node). Now we start our way back to the beginning of the computational graph and calculate the gradient (partial derivative) of the loss with respect to each node step by step. The first step is to calculate the gradient of the loss with respect to the output of the output layer $A^{[3]}$.\n",
    "\n",
    "$$\\frac{\\partial L(\\theta)}{\\partial {A^{[3]}}}=?$$\n",
    "\n",
    "> Recall that all of our calculations are matrix operations where each row is associated with one sample in the batch.  \n",
    "\n",
    "This is the Loss of the output layer:\n",
    "\n",
    "$$L(\\theta) = -\\vec{\\mathbf{y}} \\cdot \\log(A^{[3]}) - (1-\\vec{\\mathbf{y}}) \\cdot \\log(1 - A^{[3]})$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partial derivative of the loss with respect to the output of the output layer:\n",
    "\n",
    "$$\\frac{\\partial L(\\theta)}{\\partial {A^{[3]}}} = -\\frac{\\vec{\\mathbf{y}}}{A^{[3]}} + \\frac{1-\\vec{\\mathbf{y}}}{1 - A^{[3]}}$$\n",
    "\n",
    "> Note: we use chain rule for the derivative of $\\log(1 - x)$ which is $-\\frac{1}{1 - x}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, now if we substitute the values, we get:\n",
    "\n",
    "$$\\frac{\\partial L(\\theta)}{\\partial {A^{[3]}}} = \\frac{\\begin{bmatrix} 0 \\\\ -1 \\end{bmatrix}}{\\begin{bmatrix} 0.0911 \\\\ 0.7446 \\end{bmatrix}} + \\frac{\\begin{bmatrix} 1 - 0 \\\\ 1 - 1 \\end{bmatrix}}{\\begin{bmatrix} 1 - 0.0911 \\\\ 1 - 0.7446 \\end{bmatrix}}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Element-wise operation:\n",
    "\n",
    "$$\\frac{\\partial L(\\theta)}{\\partial {A^{[3]}}} = \\begin{bmatrix} \\frac{0}{0.0911} \\\\ \\frac{-1}{0.7446} \\end{bmatrix} + \\begin{bmatrix} \\frac{1}{0.9089} \\\\ \\frac{0}{0.2554} \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ -1.3430 \\end{bmatrix} + \\begin{bmatrix} 1.1003 \\\\ 0 \\end{bmatrix} = \\begin{bmatrix} 1.1003 \\\\ -1.3430 \\end{bmatrix}$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dL_dA3:\n",
      "[[ 1.1002588]\n",
      " [-1.3430085]]\n"
     ]
    }
   ],
   "source": [
    "dL_dA3 = -1 * (y_np / A3 - (1 - y_np) / (1 - A3))\n",
    "\n",
    "print(f\"dL_dA3:\\n{dL_dA3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**$X$ and $\\vec{\\mathbf{y}}$ are constants**:<br>\n",
    "In Backpropagation, the goal is find the gradient of the loss with respect to the parameters of the mode. So, the input value $X$ and the target value $\\vec{\\mathbf{y}}$ are considered as constants in our computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Gradient of $L$ with respect to $Z^{[3]}$\n",
    "\n",
    "Now in this step we go one step back in the computational graph and calculate the gradient of the loss with respect to the linear transformation of the output layer.\n",
    "\n",
    "$$\\frac{\\partial L(\\theta)}{\\partial {Z^{[3]}}}=?$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$A^{[3]}$ is a function of $Z^{[3]}$ through the Sigmoid activation function.\n",
    "\n",
    "$$A^{[3]} = \\sigma(Z^{[3]})$$\n",
    "\n",
    "Where $\\sigma$ is the Sigmoid activation function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, using the chain rule, we can write:\n",
    "\n",
    "$$\\frac{\\partial L(\\theta)}{\\partial {Z^{[3]}}} = \\frac{\\partial L(\\theta)}{\\partial {A^{[3]}}} \\cdot \\frac{\\partial {A^{[3]}}}{\\partial {Z^{[3]}}}$$\n",
    "\n",
    "We already calculated $\\frac{\\partial L(\\theta)}{\\partial {A^{[3]}}}$ in the previous step. So, we need to calculate $\\frac{\\partial {A^{[3]}}}{\\partial {Z^{[3]}}}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Sigmoid function $\\sigma(x)$:\n",
    "\n",
    "$$\\sigma(x) = \\frac{1}{1 + e^{-x}}$$\n",
    "\n",
    "The [Derivative of Sigmoid function](https://pooya.io/math/derivatives/#derivative-of-sigmoid-function) is as follows:\n",
    "\n",
    "$$\\frac{d\\sigma(x)}{dx} = \\sigma(x) \\cdot (1 - \\sigma(x))$$\n",
    "\n",
    "So, in our case, we can write the derivative of the Sigmoid function as: \n",
    "\n",
    "$$\\frac{\\partial {A^{[3]}}}{\\partial {Z^{[3]}}} = \\sigma(Z^{[3]}) \\odot (1 - \\sigma(Z^{[3]}))$$\n",
    "\n",
    "We know the $\\sigma(Z^{[3]}) = A^{[3]}$ which is the output of the model. So, we can write:\n",
    "\n",
    "$$\\frac{\\partial {A^{[3]}}}{\\partial {Z^{[3]}}} = A^{[3]} \\odot (1 - A^{[3]})$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial {A^{[3]}}}{\\partial {Z^{[3]}}} = \\begin{bmatrix} 0.0911 \\\\ 0.7446 \\end{bmatrix} \\odot \\begin{bmatrix} 1 - 0.0911 \\\\ 1 - 0.7446 \\end{bmatrix}$$\n",
    "\n",
    "Which equals to:\n",
    "\n",
    "$$\\frac{\\partial {A^{[3]}}}{\\partial {Z^{[3]}}} = \\begin{bmatrix} 0.0828 \\\\ 0.1901 \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.08281956]\n",
      " [0.19017236]]\n"
     ]
    }
   ],
   "source": [
    "dA3_dZ3 = A3 * (1 - A3)\n",
    "\n",
    "print(dA3_dZ3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can calculate the gradient.\n",
    "\n",
    "$$\\frac{\\partial L(\\theta)}{\\partial {Z^{[3]}}} = \\frac{\\partial L(\\theta)}{\\partial {A^{[3]}}}\\odot \\frac{\\partial {A^{[3]}}}{\\partial {Z^{[3]}}}= \\begin{bmatrix} 1.1003 \\\\ -1.3430 \\end{bmatrix} \\odot \\begin{bmatrix} 0.0828 \\\\ 0.1901 \\end{bmatrix}$$\n",
    "\n",
    "Which equals to:\n",
    "\n",
    "$$\\frac{\\partial L(\\theta)}{\\partial {Z^{[3]}}} = \\begin{bmatrix} 0.0911 \\\\ -0.2554 \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dL_dZ3:\n",
      "[[ 0.09112295]\n",
      " [-0.2554031 ]]\n"
     ]
    }
   ],
   "source": [
    "dL_dZ3 = dL_dA3 * dA3_dZ3\n",
    "\n",
    "print(f\"dL_dZ3:\\n{dL_dZ3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Gradient of $L$ with respect to $W^{[3]}$ and ${\\vec{\\mathbf{b}}}^{[3]}$\n",
    "\n",
    "Now we again go one step back to in the computational graph to calculate the gradient of the loss with respect to the weights and biases of the output layer (layer 3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gradient of $L$ with respect to $\\vec{\\mathbf{b}}^{[3]}$:**\n",
    "\n",
    "$$\\frac{\\partial L(\\theta)}{\\partial {\\vec{\\mathbf{b}}}^{[3]}} = ?$$\n",
    "\n",
    "The linear transformation of the output layer is:\n",
    "\n",
    "$$Z^{[3]} = A^{[2]} \\cdot {W^{[3]}}^\\top + {\\vec{\\mathbf{b}}}^{[3]}$$\n",
    "\n",
    "So, we can write the chain rule as:\n",
    "\n",
    "$$\\frac{\\partial L(\\theta)}{\\partial {\\vec{\\mathbf{b}}}^{[3]}} = \\frac{\\partial L(\\theta)}{\\partial {Z^{[3]}}} \\cdot \\frac{\\partial {Z^{[3]}}}{\\partial {\\vec{\\mathbf{b}}}^{[3]}}$$\n",
    "\n",
    "We already calculated $\\frac{\\partial L(\\theta)}{\\partial {Z^{[3]}}}$ in the previous step. So, we just need to calculate $\\frac{\\partial {Z^{[3]}}}{\\partial {\\vec{\\mathbf{b}}}^{[3]}}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial {Z^{[3]}}}{\\partial {\\vec{\\mathbf{b}}}^{[3]}} = 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we can write:\n",
    "$$\\frac{\\partial L(\\theta)}{\\partial {\\vec{\\mathbf{b}}}^{[3]}} = \\frac{\\partial L(\\theta)}{\\partial {Z^{[3]}}} \\cdot 1 = \\begin{bmatrix} 0.0911 \\\\ -0.2554 \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dL_db3:\n",
      "[[ 0.09112295]\n",
      " [-0.2554031 ]]\n"
     ]
    }
   ],
   "source": [
    "dL_db3 = dL_dZ3 * 1\n",
    "print(f\"dL_db3:\\n{dL_db3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point (when reaching model parameters), we calculate the average of these gradients over all the samples in the batch to get the gradient of the cost with respect to the biases of the output layer.\n",
    "\n",
    "$$\\frac{\\partial J(\\theta)}{\\partial {\\vec{\\mathbf{b}}}^{[3]}} = \\frac{1}{2} \\sum_{i=1}^{2} \\frac{\\partial L(\\theta)^{(i)}}{\\partial {\\vec{\\mathbf{b}}}^{[3]}} = \\frac{0.0911 - 0.2554}{2} = -0.0822$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dJ_db3:\n",
      "[-0.08214007]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the cost by averaging the gradients\n",
    "dJ_db3 = np.mean(dL_db3, axis=0)\n",
    "\n",
    "print(f\"dJ_db3:\\n{dJ_db3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our calculated gradient is the same as the PyTorch calculated gradient for bias of the layer 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient for b3:\n",
      "tensor([-0.0821])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Gradient for b3:\\n{model.linear3.bias.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gradient of $L$ with respect to $W^{[3]}$:**\n",
    "\n",
    "$$\\frac{\\partial L(\\theta)}{\\partial {W^{[3]}}}= ?$$\n",
    "\n",
    "Using the chain rule we can write:\n",
    "\n",
    "$$\\frac{\\partial L(\\theta)}{\\partial {W^{[3]}}} = \\frac{\\partial L(\\theta)}{\\partial {Z^{[3]}}} \\cdot \\frac{\\partial {Z^{[3]}}}{\\partial {W^{[3]}}}$$\n",
    "\n",
    "Again here, we already calculated $\\frac{\\partial L(\\theta)}{\\partial {Z^{[3]}}}$ in the previous step. So, we just need to calculate $\\frac{\\partial {Z^{[3]}}}{\\partial {W^{[3]}}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial {Z^{[3]}}}{\\partial {W^{[3]}}} = A^{[2]}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A2:\n",
      "[[ 0.        8.      ]\n",
      " [ 8.       10.099999]]\n"
     ]
    }
   ],
   "source": [
    "# Use calculated intermediate results during forward propagation\n",
    "A2 = model_results[\"A2\"].detach().numpy()\n",
    "\n",
    "print(f\"A2:\\n{A2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we can write:\n",
    "\n",
    "$$\\frac{\\partial L(\\theta)}{\\partial {W^{[3]}}} = \\begin{bmatrix} 0.0911 \\\\ -0.2554 \\end{bmatrix} \\odot \\begin{bmatrix} 0 & 8 \\\\ 8 & 10.1 \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Broadcasting the the first vector to the shape of $(2, 2)$ and then element-wise multiplication:\n",
    "\n",
    "$$\\frac{\\partial L(\\theta)}{\\partial {W^{[3]}}} = \\begin{bmatrix} 0 & 0.7289 \\\\ -2.0432 & -2.5795 \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dL_dW3:\n",
      "[[ 0.         0.7289836]\n",
      " [-2.0432248 -2.5795712]]\n"
     ]
    }
   ],
   "source": [
    "dL_dW3 = dL_dZ3 * A2\n",
    "\n",
    "print(f\"dL_dW3:\\n{dL_dW3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we take the average of gradients over all the samples. Each row is associated with one example in the batch. In other words, each row is the gradient of the loss with respect to the weights of the output layer for one sample. \n",
    "\n",
    "The output layer (layer 3) has only one neuron. So, we have:\n",
    "$$W^{[3]} = \\begin{bmatrix} w_{11}^{[3]} & w_{12}^{[3]} \\end{bmatrix}$$\n",
    "\n",
    "\n",
    "For example 1 in the batch:\n",
    "- $\\begin{bmatrix} 0 \\\\ -2.0432 \\end{bmatrix}$ are the gradients of the loss with respect to $w_{11}^{[3]}$ for the first and second samples in the batch, respectively.\n",
    "\n",
    "For example 2 in the batch:\n",
    "- $\\begin{bmatrix} 0.7289 \\\\ -2.5795 \\end{bmatrix}$ are the gradients of the loss with respect to $w_{12}^{[3]}$ for the first and second samples in the batch, respectively.\n",
    "\n",
    "So, the cost gradient with respect to the weights of the output layer is the mean of these gradients over all the samples in the batch.\n",
    "\n",
    "$$\\frac{\\partial J(\\theta)}{\\partial {W^{[3]}}} = \\frac{1}{2} \\sum_{i=1}^{2} \\frac{\\partial L(\\theta)^{(i)}}{\\partial {W^{[3]}}} = \\begin{bmatrix} \\frac{0 -2.0432}{2} & \\frac{0.7289 - 2.5795}{2} \\end{bmatrix} = \\begin{bmatrix} -1.0216 & -0.9253 \\end{bmatrix}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dJ_dW3:\n",
      "[-1.0216124 -0.9252938]\n"
     ]
    }
   ],
   "source": [
    "dJ_dW3 = np.mean(dL_dW3, axis=0)\n",
    "\n",
    "print(f\"dJ_dW3:\\n{dJ_dW3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is the PyTorch calculated gradient for the weights of the layer 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient of W3:\n",
      "tensor([[-1.0216, -0.9253]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Gradient of W3:\\n{model.linear3.weight.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Gradient of $L$ with respect to $A^{[2]}$\n",
    "Now, we go one step back in the computational graph to calculate the gradient of the loss with respect to the output of the layer 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial L(\\theta)}{\\partial {A^{[2]}}} = ?$$\n",
    "\n",
    "The linear transformation of the layer 3 we had:\n",
    "\n",
    "$$Z^{[3]} = A^{[2]} \\cdot {W^{[3]}}^\\top + {\\vec{\\mathbf{b}}}^{[3]}$$\n",
    "\n",
    "So, using the chain rule we can write:\n",
    "\n",
    "$$\\frac{\\partial L(\\theta)}{\\partial {A^{[2]}}} = \\frac{\\partial L(\\theta)}{\\partial {Z^{[3]}}} \\cdot \\frac{\\partial {Z^{[3]}}}{\\partial {A^{[2]}}}$$\n",
    "\n",
    "We already calculated $\\frac{\\partial L(\\theta)}{\\partial {Z^{[3]}}}$ in the previous step. So, we just need to calculate $\\frac{\\partial {Z^{[3]}}}{\\partial {A^{[2]}}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial {Z^{[3]}}}{\\partial {A^{[2]}}} = {W^{[3]}}^\\top$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W3_T:\n",
      "[[ 0.5]\n",
      " [-0.3]]\n"
     ]
    }
   ],
   "source": [
    "W3_np = W3.detach().numpy()\n",
    "W3_T_np = W3_np.T\n",
    "\n",
    "print(f\"W3_T:\\n{W3_T_np}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we can write:\n",
    "$$\\frac{\\partial L(\\theta)}{\\partial {A^{[2]}}}= \\begin{bmatrix} 0.0911 \\\\ -0.2554 \\end{bmatrix} \\odot \\begin{bmatrix} 0.5 \\\\ -0.3 \\end{bmatrix} = \\begin{bmatrix} 0.0456 \\\\ 0.0766 \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dL_dA2:\n",
      "[[0.04556147]\n",
      " [0.07662094]]\n"
     ]
    }
   ],
   "source": [
    "dL_dA2 = dL_dZ3 * W3_T_np\n",
    "\n",
    "print(f\"dL_dA2:\\n{dL_dA2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Gradient of $L$ with respect to $Z^{[2]}$\n",
    "Now we go one step back in the computational graph to calculate the gradient of the loss with respect to the linear transformation of the layer 2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$A^{[2]}$ is a function of $Z^{[2]}$ through the ReLU activation function.\n",
    "\n",
    "$$A^{[2]} = \\text{ReLU}(Z^{[2]})$$\n",
    "\n",
    "Using the chain rule we can write:\n",
    "\n",
    "$$\\frac{\\partial L(\\theta)}{\\partial {Z^{[2]}}} = \\frac{\\partial L(\\theta)}{\\partial {A^{[2]}}} \\cdot \\frac{\\partial {A^{[2]}}}{\\partial {Z^{[2]}}}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already calculated $\\frac{\\partial L(\\theta)}{\\partial {A^{[2]}}}$ in the previous step. So, we just need to calculate $\\frac{\\partial {A^{[2]}}}{\\partial {Z^{[2]}}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ReLU function is defined as:\n",
    "\n",
    "$$ReLU(x) = \\max(0, x)$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Derivative of ReLU function is as follows:\n",
    "$$\\frac{d}{dx}ReLU(x) = \\begin{cases} 0 & \\text{if } x \\leq 0 \\\\ 1 & \\text{if } x > 0 \\end{cases}$$\n",
    "\n",
    "Note: Derivative of ReLU function is not defined at $x=0$. But in practive, we can set it to $0$ or $1$. In this example we set it to $0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculated $Z^{[2]}$ in the forward propagation step.\n",
    "\n",
    "$$Z^{[2]} = \\begin{bmatrix} 0 & 8 \\\\ 8 & 10.1 \\end{bmatrix}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z2:\n",
      "[[ 0.        8.      ]\n",
      " [ 8.       10.099999]]\n"
     ]
    }
   ],
   "source": [
    "Z2 = model_results[\"Z2\"].detach().numpy()\n",
    "\n",
    "print(f\"Z2:\\n{Z2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "So, we can write:\n",
    "$$\\frac{\\partial {A^{[2]}}}{\\partial {Z^{[2]}}} = \\begin{bmatrix} 0 & 1 \\\\ 1 & 1 \\end{bmatrix}$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can calculate the gradient:\n",
    "\n",
    "$$\\frac{\\partial L(\\theta)}{\\partial {Z^{[2]}}} = \\frac{\\partial L(\\theta)}{\\partial {A^{[2]}}} \\cdot \\frac{\\partial {A^{[2]}}}{\\partial {Z^{[2]}}} = \\begin{bmatrix} 0.0456 \\\\ 0.0766 \\end{bmatrix} \\odot \\begin{bmatrix} 0 & 1 \\\\ 1 & 1 \\end{bmatrix}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Broadcasting the first vector to the shape of $(2, 2)$ and then element-wise multiplication:\n",
    "\n",
    "$$\\frac{\\partial L(\\theta)}{\\partial {Z^{[2]}}} = \\begin{bmatrix} 0 & 0.0456 \\\\ 0.0766 & 0.0766 \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dA2_dZ2:\n",
      "[[0. 1.]\n",
      " [1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the gradient of A2 with respect to Z2\n",
    "dA2_dZ2 = (Z2 > 0).astype(np.float32)\n",
    "\n",
    "print(f\"dA2_dZ2:\\n{dA2_dZ2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dL_dZ2:\n",
      "[[0.         0.04556147]\n",
      " [0.07662094 0.07662094]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the gradient of the loss with respect to Z2\n",
    "dL_dZ2 = dL_dA2 * dA2_dZ2\n",
    "\n",
    "print(f\"dL_dZ2:\\n{dL_dZ2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Gradient of $L$ with respect to $W^{[2]}$ and ${\\vec{\\mathbf{b}}}^{[2]}$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
