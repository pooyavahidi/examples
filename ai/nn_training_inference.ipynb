{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0b8734b",
   "metadata": {},
   "source": [
    "# Training and Inference in Neural Networks\n",
    "In this example, let's look at a complete cycle of training and inference in a neural network. We will assume that our data is already preprocessed and is ready for training. We will show a simple but practical example using PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4a595c",
   "metadata": {},
   "source": [
    "We will use the MNIST dataset, which consists of handwritten digits from 0 to 9. We will build a neural network to classify these digits. So, this is a _classification_ problem with 10 classes (digits 0 to 9). \n",
    "\n",
    "In this example, we keep the model and steps simple. For a more advanced implementation, see [this official PyTorch example](https://github.com/pytorch/examples/blob/main/mnist/main.py).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ff43ad",
   "metadata": {},
   "source": [
    "## Data\n",
    "As always in machine learning, we start with exploring our data and [Exploratory Data Analysis (EDA)](https://pooya.io/ai/ai_machine_learning_overview/#exploratory-data-analysis-eda-and-feature-engineering)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f893a7",
   "metadata": {},
   "source": [
    "The MNIST dataset contains 60,000 training images and 10,000 test images. \n",
    "- Each image is 28x28 pixels, and the labels are the digits from 0 to 9.\n",
    "- The images are grayscale (one channel), so the pixel values range from 0 to 255, which is the brightness (intensity) of the pixel.\n",
    "- The dataset is split into a training set and a test set.\n",
    "\n",
    "The training data set is a matrix of 60,000 rows and 28x28x1= 784 columns. Each row represents a single image, which has 784 columns (features).\n",
    "\n",
    "$$Channel \\times Height \\times Width = 1 \\times 28 \\times 28 = 784$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cdbf20",
   "metadata": {},
   "source": [
    "\n",
    "$$X_{\\text{train}} \\in \\mathbb{R}^{60000 \\times 784}$$\n",
    "\n",
    "$$X_{\\text{train}} = \\begin{bmatrix}\n",
    "\\vec{\\mathbf{x}}^{(1)} \\\\\n",
    "\\vec{\\mathbf{x}}^{(2)} \\\\\n",
    "\\vdots \\\\\n",
    "\\vec{\\mathbf{x}}^{(60000)}\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "Where:\n",
    "- $\\vec{\\mathbf{x}}^{(i)} \\in \\mathbb{R}^{784}$ is the $i$-th image in the training set.\n",
    "\n",
    "$X_{\\text{test}}$ similarly is a matrix of 10,000 rows and 784 columns.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426209d5",
   "metadata": {},
   "source": [
    "The labels are a vector of same size (60,000) as the number of training images. Each label is an integer from 0 to 9, representing the digit in the corresponding image.\n",
    "\n",
    "$$y_{\\text{train}} \\in \\mathbb{R}^{60000}$$\n",
    "\n",
    "Similarly, $y_{\\text{test}}$ is a vector of size 10,000.\n",
    "\n",
    "$$y_{\\text{test}} \\in \\mathbb{R}^{10000}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2092cb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35477663",
   "metadata": {},
   "source": [
    "Let's download the MNIST dataset using `torchvision` offered by PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd62e980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transformation to be applied to the images\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Download the MNIST training and test datasets\n",
    "train_data = datasets.MNIST(\n",
    "    root=\"data\", train=True, download=True, transform=transform\n",
    ")\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\", train=False, download=True, transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65c402c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: torch.Size([60000, 28, 28]), dtype: torch.uint8\n",
      "y_train shape: torch.Size([60000])\n",
      "X_test shape: torch.Size([10000, 28, 28]), dtype: torch.uint8\n",
      "y_test shape: torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"X_train shape: {train_data.data.shape}, dtype: {train_data.data.dtype}\"\n",
    ")\n",
    "print(f\"y_train shape: {train_data.targets.shape}\")\n",
    "\n",
    "print(f\"X_test shape: {test_data.data.shape}, dtype: {test_data.data.dtype}\")\n",
    "print(f\"y_test shape: {test_data.targets.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2011de6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First image shape: torch.Size([28, 28])\n",
      "First image label: 5\n"
     ]
    }
   ],
   "source": [
    "print(f\"First image shape: {train_data.data[0].shape}\")\n",
    "print(f\"First image label: {train_data.targets[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ca4869",
   "metadata": {},
   "source": [
    "**Labels:**\n",
    "\n",
    "In MNIST dataset, where we are classifying handwritten digits from 0 to 9, the labels are simply the digits themselves. In other words, the class 0 (label 0) corresponds to the digit 0, class 1 (label 1) corresponds to the digit 1, and so on.\n",
    "\n",
    "| Class (Label) | Value |\n",
    "|---------------|-------|\n",
    "| 0             | 0     |\n",
    "| 1             | 1     |\n",
    "| 2             | 2     |\n",
    "| 3             | 3     |\n",
    "| 4             | 4     |\n",
    "| 5             | 5     |\n",
    "| 6             | 6     |\n",
    "| 7             | 7     |\n",
    "| 8             | 8     |\n",
    "| 9             | 9     |\n",
    "\n",
    "However, in a more complex dataset, the labels are not always integers. For example, in [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist?tab=readme-ov-file#labels), the labels are strings representing the class names. The labels are as follows:\n",
    "\n",
    "| Class (Label) | Value |\n",
    "|---------------|-------|\n",
    "| 0             | T-shirt/top |\n",
    "| 1             | Trouser     |\n",
    "| 2             | Pullover    |\n",
    "| ...           | ...         |\n",
    "\n",
    "So, this is important to note that regardless of the actual value of the classes, we always map them to integers starting from 0 which in that case the logits of the output layer are automatically mapped to the corresponding index of the class. For example, $z_{0}$ will be mapped to class 0, $z_{1}$ will be mapped to class 1, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1e193e",
   "metadata": {},
   "source": [
    "**Batching:**\n",
    "\n",
    "In PyTorch, we wrap our dataset in a `DataLoader` object which allows us to iterate over the dataset in batches and support shuffling, sampling, and multi-processing. The `DataLoader` object is the one that feeds the data to the model batch by batch.\n",
    "\n",
    "We define batch size as 64. It means in each iteraction of the training (Gradient Descent) we will use 64 images to calculate the cost, and gradients and then update the parameters of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52ec2f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3628ef",
   "metadata": {},
   "source": [
    "As we saw earlier our training data is 3D matrix of size (60000, 28, 28). In other words, we have 60,000 examples which each is a 28x28 pixels image. So, overall we have a matrix of 60,000 rows which each row is a matrix of 28 rows and 28 columns.\n",
    "\n",
    "However, as soon as we wrap it in the `DataLoader` object, then it breaks down the whole dataset into batch size chunks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3935fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [Batch size, Channel, Height, Weight]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "for X, y in train_dataloader:\n",
    "    print(f\"Shape of X [Batch size, Channel, Height, Weight]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1de1dff",
   "metadata": {},
   "source": [
    "## Creating the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82068b60",
   "metadata": {},
   "source": [
    "In this example we create a very simple model using 3 fully connected layers (also called linear layers, or Dense layers). \n",
    "\n",
    "**Layer 1 (Dense):**\n",
    "- $28 \\times 28 \\times 1 = 784$ inputs, $512$ outputs\n",
    "- Activation function: ReLU\n",
    "- In this layer we have $512$ neurons. the shape of matrix $W1$ is (512, 784) and the shape of vector $b1$ is (512,)\n",
    "\n",
    "**Layer 2 (Dense):**\n",
    "- $512$ inputs, $512$ outputs.\n",
    "- Activation function: ReLU\n",
    "- In this layer we have $512$ neurons. the shape of matrix $W2$ is (512, 512) and the shape of vector $b2$ is (512,)\n",
    "\n",
    "**Layer 3 (Dense):**\n",
    "- $512$ inputs, $10$ outputs (one for each class)\n",
    "- Activation function: None (linear Activation)\n",
    "- In this layer we have $10$ neurons. the shape of matrix $W3$ is (10, 512) and the shape of vector $b3$ is (10,)\n",
    "\n",
    "**Placement of Activation Function for the Output Layer:**<br>\n",
    "\n",
    "As we discussed [here](), the output layer's activation function is applied separately to the logits of the output layer. In here, we have a multi-class classification problem, so we will use the softmax activation function. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1430f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.linear1 = nn.Linear(in_features=28 * 28, out_features=512)\n",
    "        self.linear2 = nn.Linear(in_features=512, out_features=512)\n",
    "        self.linear3 = nn.Linear(in_features=512, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
